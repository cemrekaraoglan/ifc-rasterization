{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "import numpy as np\n",
    "from typing import Any, Tuple\n",
    "from importlib import reload\n",
    "import multiprocessing\n",
    "import ifcopenshell\n",
    "import ifcopenshell.geom\n",
    "import time\n",
    "from functools import reduce\n",
    "import open3d as o3d\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "from csv import writer\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_color():\n",
    "    \"\"\"Generate a random RGB color.\"\"\"\n",
    "    return [random.random(), random.random(), random.random()]\n",
    "\n",
    "def open3d_block_by_element(ifc_file): \n",
    "    # Configuration for ifcopenshell geometric settings\n",
    "    settings = ifcopenshell.geom.settings()\n",
    "    settings.set(settings.USE_WORLD_COORDS, True)\n",
    "    settings.set(settings.APPLY_DEFAULT_MATERIALS, True)\n",
    "\n",
    "    # Initialize the iterator for geometric representations\n",
    "    iterator = ifcopenshell.geom.iterator(settings, ifc_file, multiprocessing.cpu_count())\n",
    "    \n",
    "    # Define entity types to include and exclude\n",
    "    exclude_list = set([\"IfcCovering\", \"IfcFurnishingElement\", \"IfcSpace\", \"IfcOpening\", \"IfcOpeningElement\", \"IfcRailing\"])\n",
    "    \n",
    "    # Lists to store the resulting meshes and element information\n",
    "    all_meshes = []\n",
    "    element_information = {}\n",
    "    \n",
    "    # Variable to track the smallest dimension among all meshes\n",
    "    temp_dimension = 5.0\n",
    "    \n",
    "\n",
    "    # Iterate over the geometric representations\n",
    "    if iterator.initialize():\n",
    "        index = 0\n",
    "        while True:\n",
    "            shape = iterator.get()\n",
    "            \n",
    "            # Check if the shape type is not excluded and represents an IfcBuildingElement\n",
    "            if shape.type not in exclude_list and shape.product.is_a(\"IfcBuildingElement\"):\n",
    "                # Convert the shape's geometry to an Open3D mesh\n",
    "                faces = np.array(shape.geometry.faces)\n",
    "                verts = np.array(shape.geometry.verts).reshape(-1, 3)\n",
    "                mesh = o3d.geometry.TriangleMesh(vertices=o3d.utility.Vector3dVector(verts),\n",
    "                                                 triangles=o3d.utility.Vector3iVector(faces.reshape(-1, 3)))\n",
    "                \n",
    "                # Update the smallest dimension if necessary\n",
    "                min_dimension = min(mesh.get_max_bound() - mesh.get_min_bound())\n",
    "                if min_dimension >= 0.1 and temp_dimension > min_dimension:\n",
    "                    temp_dimension = round(float(min_dimension), 2)\n",
    "                \n",
    "                # Store the mesh and its corresponding IFC GUID\n",
    "                all_meshes.append(mesh)\n",
    "                element_information[index] = shape.guid\n",
    "                index += 1\n",
    "                    \n",
    "            # Move to the next geometric representation\n",
    "            if not iterator.next():\n",
    "                break\n",
    "\n",
    "    return all_meshes, element_information, temp_dimension\n",
    "\n",
    "def create_uniform_grid(bounds, voxel_size):\n",
    "    \"\"\"Create a uniform grid within the given bounds.\"\"\"\n",
    "    x = np.arange(bounds[0], bounds[1] + voxel_size, voxel_size)\n",
    "    y = np.arange(bounds[2], bounds[3] + voxel_size, voxel_size)\n",
    "    z = np.arange(bounds[4], bounds[5] + voxel_size, voxel_size)\n",
    "    return pv.StructuredGrid(*np.meshgrid(x, y, z))\n",
    "\n",
    "def open3d_to_pyvista(point_cloud_o3d):\n",
    "    \"\"\"\n",
    "    Convert an Open3D point cloud to a PyVista point cloud.\n",
    "\n",
    "    Parameters:\n",
    "    - point_cloud_o3d: The Open3D point cloud.\n",
    "\n",
    "    Returns:\n",
    "    - A PyVista `PolyData` object.\n",
    "    \"\"\"\n",
    "    # Extract points from Open3D point cloud\n",
    "    points = np.asarray(point_cloud_o3d.points)\n",
    "\n",
    "    # Create a PyVista PolyData object\n",
    "    point_cloud_pv = pv.PolyData(points)\n",
    "\n",
    "    return point_cloud_pv\n",
    "\n",
    "def process_point(pcd, mesh_guid_index, grid_bounds, voxel_size, dims, grid_attributes):\n",
    "    j = int((pcd[0] - grid_bounds[0]) / voxel_size)\n",
    "    i = int((pcd[1] - grid_bounds[2]) / voxel_size)\n",
    "    k = int((pcd[2] - grid_bounds[4]) / voxel_size)\n",
    "    \n",
    "    if 0 <= i < dims[0]-1 and 0 <= j < dims[1]-1 and 0 <= k < dims[2]-1 and grid_attributes[i,j,k] == -1:\n",
    "        grid_attributes[i,j,k] = mesh_guid_index\n",
    "\n",
    "def voxelize_space(bounds, pcd_list, voxel_size):\n",
    "    \"\"\"Create a 3d grid and check the intersections of the meshes with the grid.\"\"\"\n",
    "    grid = create_uniform_grid(bounds, voxel_size)\n",
    "    \n",
    "    # create an empty 3d array in the same dimensions of the grid\n",
    "    dims = grid.dimensions\n",
    "    grid_attributes = np.full((dims[0]-1, dims[1]-1, dims[2]-1), -1, dtype=int)\n",
    "\n",
    "    grid_bounds = grid.bounds\n",
    "    \n",
    "    [process_point(point, i, grid_bounds, voxel_size, dims, grid_attributes) \n",
    "    for i, pcd in enumerate(pcd_list) for point in pcd.points]\n",
    "\n",
    "    # assign empty array to the grid\n",
    "    grid.cell_data['attributes'] = grid_attributes.flatten(order='F').astype(int)\n",
    "    \n",
    "    return grid\n",
    "\n",
    "def get_sampling_points(mesh, voxel_size, points_per_unit_area=120):\n",
    "    \n",
    "    # Calculate the surface area of the mesh\n",
    "    area = mesh.get_surface_area()\n",
    "\n",
    "    # Calculate the number of points to sample\n",
    "    N = int(area * points_per_unit_area*1/voxel_size)\n",
    "        \n",
    "    return N\n",
    "\n",
    "def create_point_cloud(all_meshes, voxel_size):\n",
    "    \"\"\"Create a point cloud from a mesh.\"\"\"\n",
    "\n",
    "    pcd_list = []\n",
    "\n",
    "    for mesh in all_meshes:\n",
    "        # Get the number of points to sample based on the mesh size\n",
    "        N = get_sampling_points(mesh, voxel_size)\n",
    "        pcd = mesh.sample_points_uniformly(N)\n",
    "        pcd_pv = open3d_to_pyvista(pcd)\n",
    "        pcd_list.append(pcd_pv)  \n",
    "        \n",
    "    return pcd_list\n",
    "\n",
    "\n",
    "def fetch_element_quantities(ifc_file, grid, voxel_size, element_information):\n",
    "    # Fetch all property sets named 'ZECH_ATTRIBUTE'\n",
    "    property_sets = ifc_file.by_type(\"IfcPropertySet\")\n",
    "    zech_property_sets = [ps for ps in property_sets if ps.Name == \"ZECH_ATTRIBUTE\"]\n",
    "    \n",
    "    # Create a mapping of elements to their ZB_AUSWAHL values\n",
    "    element_to_zb_auswahl = {}\n",
    "    for ps in zech_property_sets:\n",
    "        for prop in ps.HasProperties:\n",
    "            if prop.is_a(\"IfcPropertySingleValue\") and prop.Name == \"ZB_AUSWAHL\":\n",
    "                # Find all elements that have this property set\n",
    "                for rel in ifc_file.by_type(\"IfcRelDefinesByProperties\"):\n",
    "                    if rel.RelatingPropertyDefinition == ps:\n",
    "                        for related_object in rel.RelatedObjects:\n",
    "                            element_to_zb_auswahl[related_object.GlobalId] = str(prop.NominalValue.wrappedValue)\n",
    "    \n",
    "    element_volumes = defaultdict(int)\n",
    "    \n",
    "    # Calculate volumes\n",
    "    for att in grid.cell_data['attributes']:\n",
    "        element_guid = element_information.get(att)\n",
    "        zb_auswahl_value = element_to_zb_auswahl.get(element_guid)\n",
    "        if zb_auswahl_value is not None:\n",
    "            element_volumes[zb_auswahl_value] += 1\n",
    "    \n",
    "    # Convert counts to volumes\n",
    "    for zb_auswahl_value, count in element_volumes.items():\n",
    "        element_volumes[zb_auswahl_value] = round(count * voxel_size**3, 3)\n",
    "    \n",
    "    return element_volumes\n",
    "\n",
    "def kabsch(P, Q):\n",
    "    \"\"\"\n",
    "    P and Q are Nx3 matrices of corresponding points.\n",
    "    Returns the rotation matrix to align P with Q.\n",
    "    \"\"\"\n",
    "    # Step 1 & 2: Find centroids and center points\n",
    "    centroid_P = np.mean(P, axis=0)\n",
    "    centroid_Q = np.mean(Q, axis=0)\n",
    "    P_centered = P - centroid_P\n",
    "    Q_centered = Q - centroid_Q\n",
    "    \n",
    "    # Step 3: Compute covariance matrix\n",
    "    H = np.dot(P_centered.T, Q_centered)\n",
    "    \n",
    "    # Step 4: SVD\n",
    "    U, S, Vt = np.linalg.svd(H)\n",
    "    \n",
    "    # Step 5 & 6: Compute rotation matrix and handle reflections\n",
    "    R = np.dot(Vt.T, U.T)\n",
    "    if np.linalg.det(R) < 0:\n",
    "        U[:, -1] = -U[:, -1]\n",
    "        R = np.dot(Vt.T, U.T)\n",
    "    \n",
    "    return R\n",
    "\n",
    "def process_ifc_file(file_name, writer):\n",
    "    try:\n",
    "        \n",
    "        pv.set_plot_theme(\"document\")\n",
    "        pv.global_theme.window_size = [1024, 768]\n",
    "        pv.global_theme.jupyter_backend = 'trame'\n",
    "        p = pv.Plotter()\n",
    "        ifc_file = ifcopenshell.open(file_name)\n",
    "        print(file_name)\n",
    "\n",
    "        ### CONVERSION FROM IFC TO MESH ###\n",
    "        print(f'Converting {file_name}...')\n",
    "\n",
    "        start_time = time.time()\n",
    "        all_meshes, element_information, voxel_size = open3d_block_by_element(ifc_file)\n",
    "\n",
    "        total_polygons = sum(len(mesh.triangles) for mesh in all_meshes)\n",
    "\n",
    "        # combine all meshes into one mesh and find the bounds\n",
    "        combined_mesh = reduce(lambda m1, m2: m1 + m2, all_meshes)\n",
    "\n",
    "\n",
    "        ####################################################################################\n",
    "        '''obb = combined_mesh.get_oriented_bounding_box()\n",
    "        obb_points_o3d = np.asarray(obb.get_box_points())\n",
    "        obb_points_pcl = pv.PolyData(obb_points_o3d)\n",
    "        \n",
    "        aabb = combined_mesh.get_axis_aligned_bounding_box()\n",
    "        aabb_points_o3d = np.asarray(aabb.get_box_points())\n",
    "        aabb_points_pcl = pv.PolyData(aabb_points_o3d)\n",
    "\n",
    "        R = kabsch(aabb_points_pcl.points, obb_points_pcl.points)'''\n",
    "\n",
    "        '''rotated_meshes = []\n",
    "        for mesh in all_meshes:\n",
    "            # Get the vertices of the mesh\n",
    "            vertices = np.asarray(mesh.vertices)\n",
    "            \n",
    "            # Apply the rotation\n",
    "            rotated_vertices = vertices.dot(R.T)\n",
    "            \n",
    "            # Update the mesh vertices\n",
    "            mesh.vertices = o3d.utility.Vector3dVector(rotated_vertices)\n",
    "            rotated_meshes.append(mesh)\n",
    "        combined_mesh_2 = reduce(lambda m1, m2: m1 + m2, rotated_meshes)'''\n",
    "        end_time = time.time()\n",
    "        conversion_time = end_time - start_time\n",
    "\n",
    "        ####################################################################################\n",
    "\n",
    "\n",
    "        ### POINT CLOUD CREATION ###\n",
    "        print(f'Point cloud formation representing {file_name}...')\n",
    "        start_time = time.time()\n",
    "        point_cloud_list  = create_point_cloud(all_meshes, voxel_size)\n",
    "        \n",
    "        #merge all the list of point clouds into one\n",
    "        pcd_pv = pv.PolyData()\n",
    "        pcd_pv.points = np.vstack(list(map(lambda x: x.points, point_cloud_list)))\n",
    "        sampling_points = len(pcd_pv.points)\n",
    "        end_time = time.time()\n",
    "        point_cloud_processing = end_time - start_time\n",
    "\n",
    "        print(f'Rasterizing {file_name}...')\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Compute the oriented bounding box (OBB)\n",
    "        bb = combined_mesh.get_axis_aligned_bounding_box()\n",
    "        \n",
    "        # Extract the eight corner points of the OBB\n",
    "        bb_points = np.asarray(bb.get_box_points())\n",
    "\n",
    "        # Compute the axis-aligned bounding box of these eight points\n",
    "        xmin, ymin, zmin = np.min(bb_points, axis=0)\n",
    "        xmax, ymax, zmax = np.max(bb_points, axis=0)\n",
    "\n",
    "        bounds = np.array([xmin, xmax, ymin, ymax, zmin, zmax])\n",
    "        \n",
    "        ### RASTERIZATION ###\n",
    "        \n",
    "        grid = voxelize_space(bounds, point_cloud_list, voxel_size)\n",
    "        end_time = time.time()\n",
    "        rasterization_time = end_time - start_time\n",
    "        \n",
    "        end_time = time.time()\n",
    "        rasterization_time = end_time - start_time        \n",
    "\n",
    "        ### VISUALIZATION ###\n",
    "        print(f'Visualizing {file_name}...')\n",
    "        start_time = time.time()\n",
    "         \n",
    "        # Extract the cells with non-empty attribute values\n",
    "        non_empty_cells = grid.cell_data['attributes'] != -1  \n",
    "        # Create a box from the bounds\n",
    "        box = pv.Box(bounds=bounds)\n",
    "\n",
    "        # Add the box to the plotter\n",
    "        p.add_mesh(box, color=\"blue\", style=\"wireframe\", line_width=2)\n",
    "        # Add the mesh to the plotter with the non-empty cells\n",
    "        p.add_mesh(grid.extract_cells(non_empty_cells), opacity=0.5, show_edges=False,show_scalar_bar=False)\n",
    "        \n",
    "        screenshot_filename = os.path.join(\"screenshots\", os.path.basename(file_name) + \".png\")\n",
    "        p.screenshot(screenshot_filename)\n",
    "        end_time = time.time()\n",
    "        visualization_time = end_time - start_time\n",
    "        p.show()\n",
    "         # Store the results in a dictionary\n",
    "        results = {}\n",
    "        results['File'] = file_name\n",
    "        results['# of Polygons'] = total_polygons\n",
    "        results['# of Points'] = sampling_points\n",
    "        results['Cell Size (m)'] = voxel_size\n",
    "        results['Conversion (sec)'] = round(conversion_time,2)\n",
    "        results['Point Cloud Creation (sec)'] = round(point_cloud_processing,2)\n",
    "        results['Rasterization (sec)'] = round(rasterization_time,2)\n",
    "        results['Visualization (sec)'] = round(visualization_time,2)\n",
    "        \n",
    "        print(f'Calculating quantities in {file_name}...')\n",
    "        \n",
    "        start_time = time.time()\n",
    "        element_volumes = fetch_element_quantities(ifc_file, grid, voxel_size, element_information)\n",
    "\n",
    "        results_QTO = {}\n",
    "\n",
    "        # Store the concrete volumes for different ZB_AUSWAHL values\n",
    "        for zb_auswahl_value, volume in element_volumes.items():\n",
    "            results_QTO[f'{zb_auswahl_value}'] = volume\n",
    "\n",
    "        end_time = time.time()\n",
    "        quantity_calculation_time = end_time - start_time\n",
    "        results['Quantity Calculation (sec)'] = quantity_calculation_time\n",
    "\n",
    "        print(results)\n",
    "        print(results_QTO)\n",
    "\n",
    "        # Write results to Excel\n",
    "        df_results = pd.DataFrame([results])\n",
    "        df_results_QTO = pd.DataFrame([results_QTO])\n",
    "        df_results_QTO = df_results_QTO\n",
    "\n",
    "        # Find the last row in the Excel sheets\n",
    "        last_row_results = writer.sheets['Results'].max_row\n",
    "        last_row_qto = writer.sheets['QTO'].max_row\n",
    "\n",
    "        # Write the dataframes to Excel, starting at the last row\n",
    "        df_results.to_excel(writer, sheet_name='Results', startrow=last_row_results, index=False, header=False)\n",
    "        df_results_QTO.T.to_excel(writer, sheet_name='QTO', startrow=last_row_qto, header=True)\n",
    "        screenshot_filename = os.path.join(\"screenshots\", os.path.basename(file_name) + \".png\")\n",
    "        p.screenshot(screenshot_filename)\n",
    "\n",
    "        # Ensure that the writer object is returned'''\n",
    "        return writer\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {file_name} not found.\")\n",
    "        print(\"Here's the traceback:\")\n",
    "        traceback.print_exc()\n",
    "        return {}, {}\n",
    "\n",
    "    except MemoryError:\n",
    "        print(f\"Error: Insufficient memory to process {file_name}.\")\n",
    "        print(\"Here's the traceback:\")\n",
    "        traceback.print_exc()\n",
    "        return {}, {}\n",
    "\n",
    "    except (TypeError, ValueError) as e:\n",
    "        print(f\"Error processing {file_name}: {str(e)}\")\n",
    "        print(\"Here's the traceback:\")\n",
    "        traceback.print_exc()\n",
    "        return {}, {}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while processing {file_name}: {str(e)}\")\n",
    "        print(\"Here's the traceback:\")\n",
    "        traceback.print_exc()\n",
    "        return {}, {}\n",
    "    \n",
    "def find_ifc_files(directory):\n",
    "    \"\"\"Find all IFC files in a given directory.\"\"\"\n",
    "    # Use os.path.join to ensure the path is constructed correctly for any OS\n",
    "    search_path = os.path.join(directory, \"*.ifc\")\n",
    "    return glob.glob(search_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current date and time\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# Format the date and time as a string: YYYYMMDD_HHMMSS\n",
    "formatted_time = now.strftime(\"%Y_%m_%d\")\n",
    "\n",
    "# Create a filename using the formatted time\n",
    "filename = f\"output_{formatted_time}.xlsx\"\n",
    "\n",
    "# Ensure the writer context is used when calling process_ifc_file\n",
    "with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
    "    \n",
    "    # Create initial empty DataFrames to set up the Excel sheets\n",
    "    pd.DataFrame(columns=['File', '# of Polygons', '# of Points', 'Cell Size (m)', 'Conversion Time (sec)', 'Point Cloud Creation Time (sec)', 'Rasterization (sec)', 'Visualization (sec)', 'Concrete Calculation Time (sec)']).to_excel(writer, sheet_name='Results')\n",
    "    pd.DataFrame().to_excel(writer, sheet_name='QTO')  # Add appropriate columns if needed\n",
    "    \n",
    "    # Call process_ifc_file within the writer context\n",
    "    process_ifc_file(\"IFC Files/01_Test.ifc\", writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''directory_path = \"IFC Files/\"\n",
    "ifc_files = find_ifc_files(directory_path)\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# Format the date and time as a string: YYYYMMDD_HHMMSS\n",
    "formatted_time = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Create a filename using the formatted time\n",
    "filename = f\"output_{formatted_time}.xlsx\"\n",
    "\n",
    "# Create an Excel writer object\n",
    "# Ensure the writer context is used when calling process_ifc_file\n",
    "with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
    "    # Create initial empty DataFrames to set up the Excel sheets\n",
    "    pd.DataFrame(columns=['File', '# of Polygons', '# of Points', 'Cell Size (m)', 'Conversion Time (sec)', 'Point Cloud Creation Time (sec)', 'Rasterization (sec)', 'Visualization (sec)', 'Concrete Calculation Time (sec)']).to_excel(writer, sheet_name='Results')\n",
    "    pd.DataFrame().to_excel(writer, sheet_name='QTO')  # Add appropriate columns if needed\n",
    "      \n",
    "    # Process each IFC file and write the results to Excel\n",
    "    for file_name in ifc_files:\n",
    "        process_ifc_file(file_name, writer)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
